---
title: 'Guia para utilizar os metamodelos que estimam o desempenho térmico de unidades habitacionais'
author: 'LabEEE - Rodolfo Kirch Veiga (rodolfoksveiga@gmail.com)'
date: 'Florianópolis, 02 de Outubro de 2020'
output:
  html_document: default
  pdf_document: default
subtitle: 'Em acordo com a nova proposta para a NBR 15575'
---

```{r include = FALSE}
library(knitr)
  opts_chunk$set(echo = TRUE, comment = '')
```

***

## Objetivo

Esse guia tem como objetivo descrever o procedimento para estimar o desempenho térmico de unidades habitacionais (UHs) uni e multifamiliares, seguindo as premissas da **nova proposta para NBR 15575**. As predições de desempenho serão realizadas na linguagem de programação **R**, através de um modelo de aprendizado de máquinas (metamodelo) previamente treinado e testado pela equipe do **Laboratório de Eficiência Energética (LabEEE)** da **Universidade Federal de Santa Catarina (UFSC)**, em uma parceria com a empresa **Saint Gobain**.

Todos os arquivos relacionados a esse projeto podem ser encontrados nesse [*link*](https://github.com/rodolfoksveiga/saint_gobain).

***

### Dependências

Para reproduzir o que foi descrito nesse documento é necessário que o usuário possua instalados em sua máquina local a linguagem [R](https://www.r-project.org/), versão 4.0.2, e os seguintes pacotes:

1. [caret](https://cran.r-project.org/web/packages/caret/index.html), versão 6.0-86
2. [dplyr](https://cran.r-project.org/web/packages/dplyr/index.html), versão 1.0.2
3. [purrr](https://cran.r-project.org/web/packages/purrr/index.html), versão 0.3.4

\

Para instalar esses pacotes o usuário deve abrir o console na linguagem **R** e executar o código abaixo. O uso da IDE [RStudio](https://rstudio.com/) pode facilitar a execução e o acompanhamento dos resultados dos códigos que seguem.

\

``` {r eval = FALSE}
  install.packages('devtools')
  pkgs = c('caret', 'dplyr', 'purrr')
  vrs = c('6.0-86', '1.0.2', '0.3.4')
  mapply(devtools::install_version, pkgs, vrs)
```

\

Além disso, é necessário que os seguintes arquivos estejam **localizados no mesmo diretório**:

1. **predict_outputs.r** ([*link* para *download*](https://drive.google.com/uc?export=download&id=1kCJYMu2rNBbtG7N4BvmD7ugDFKxosLOD))
2. **models.rds** ([*link* para *download*](https://drive.google.com/uc?export=download&id=12qCwPNFevstfo89JdRuIPf-eMWDOQ1lc))

***

### Características dos metamodelos {.tabset .tabset-pills}

A base de dados gerada para treinar os metamodelos foi desenvolvida perturbando-se dois modelos de simulação base, referentes à: a) uma tipologia unifamiliar térrea, e; b) uma tipologia multifamiliar, composta por pavimento térreo, tipo e cobertura. As características de ambas as tipologias foram extraídas do levantamento de edificações residenciais brasileiras de baixa renda, realizado por [Montes (2016)](https://repositorio.ufsc.br/handle/123456789/176656).

A partir das perturbações e da implementação do método de amostragem *Latin Hypercube*, códigos escritos na linguagem [Python 3](https://www.python.org/) geraram, de forma automatizada, **10000** modelos de simulação para a tipologia unifamiliar e **53760** para a tipologia multifamiliar. Para cada modelo de simulação foi gerado também seu respectivo modelo de referência, como exige a **nova proposta para a NBR 15575**. Todas as simulações foram executadas no programa [EnergyPlus](https://energyplus.net/), versão 9.0.1, e através dos resultados das simulações foram calculados os seguintes dados de saída: a) percentual de horas ocupadas em que o ambiente encontra-se dentro de uma determinada faixa de temperatura (PHFT), e; b) somatório das cargas térmicas de refrigeração e aquecimento quando o ambiente está ocupado e encontra-se com temperatura fora da faixa pré-determinada (CgTT).

Detalhes sobre a modelagem e o cálculo dos dados de saída podem ser encontrados na [nova proposta para NBR 15575](link).

Através da base de dados foram treinados e testados metamodelos utilizando as seguintes técnicas: *Linear Regression*, *Support Vector Machine with Radial Kernel*, *Bayesian Neural Networks*, *Boosted Tree* e *Extreme Gradient Boosting*. No pre-processamento da base de dados, as variáveis de entrada quantitativas foram transformadas através da técnica *BoxCox* e as variáveis de entrada qualitativas foram transformadas em variáveis lógicas, também conhecidas como *Dummy Variables*. Todos os metamodelos foram treinados através do pacote [caret](https://topepo.github.io/caret/), da linguagem **R**.

A tabela abaixo apresenta a estatística descritiva dos metamodelos finais, ou seja, aqueles que apresentaram os resultados mais acurados na etapa de teste, i.e. menores erro médio absoluto (MAE) e raíz do erro quadrático médio (RMSE). Os metamodelos mais acurados foram alcançados através da técnica [*Extreme Gradient Boosting*](https://xgboost.ai/).

\

``` {r echo = FALSE, message = FALSE}
  kable(read.csv('./plot_table/summ_stats.csv'), align = 'c')
```

\

Para predizer cada um dos dados de saída foi elaborado um metamodelo diferente. Entretanto, o usuário final não deve se ater a esses detalhes, pois o código ofericido realiza todas as rotinas de cálculo necessárias e retorna uma tabela com os valores das variáveis de entrada fornecidas e dos respectivos valores das variáveis de saída.

\

#### **Variáveis de entrada (*inputs*)**

* `area` (m²): área total do piso da UH
  + Unifamiliar (uni): 39, 58 e 77
  + Multifamiliar (multi): 34, 35, 51 e 52
* `ratio` (adim.): relação entre o comprimento e a profundidade do edifício - $ratio = lx/ly$
  + Uni: 0.5, 1 e 2.5
  + Multi: 0.5, 1 e 2
* `pav` (qualitativa): pavimento onde encontra-se a UH
  + Multi: "terreo" (térreo), "inter" (intermediário) e "cob" (cobertura)
* `solo` (qualitativa): exposição do pavimento térreo do edifício ao solo
  + Multi: "solo" (exposto ao solo) e "pilotis" (edifício sobre pilotis)
* `exp` (qualitativa) : exposição das paredes da UH
  + Multi: "canto" (duas fachadas expostas) e "meio" (uma fachada exposta)
* `pd` (m): pé-direito
  + Uni: 2.5 e 5
* `azi` (°): ângulo azimutal
  + Uni/Multi: 0, 90, 180 e 270
* `comp` (qualitativa): composição dos componentes construtivos
  + Uni/Multi: "ref" (concreto de 10 cm), "tv" (tjolo vazado), "tm10" (tijolo maciço de 10 cm), "tm20" (tijolo maciço de 20 cm), "sfar" (*steel frame* isolado com ar), "sfiso" (*steel frame* isolado com lã de vidro)
* `vid`: composição dos vidros
  + Uni/Multi: "simples_fs87" (vidro simples com 0.87 de FS), "simples_fs39" (vidro simples com 0.39 de FS), "duplo_fs87-87" (vidro duplo com FS de 0.87), "duplo_fs39-87" (vidro duplo com FS = 0.39 e 0.87)
* `abs` (adim.): absortância solar
  + Uni/Multi: 0.2, 0.6 e 0.8
* `paf` (%): percentual envidraçado das fachadas
  + Uni/Multi: 10, 30 e 50
* `fv` (adim.): fator de ventilação
  + Uni/Multi: 0.45 e 1
* `ven` (qualitative): condição das venezianas
  + Uni/Multi: "on" (com veneziana) e "off" (sem possui veneziana)
* `somb` (cm): comprimento do sombreamento horizontal sobre todas as fachadas
  + Uni: 0, 50 e 150
  + Multi: 0 e 120
* `tbsm` (°): média anual da temperatura de bulbo seco
  + Uni/Multi: 17.38, 19.04, 20.91, 22.95, 23.05, 23.92, 26.76, 26.82

#### **Variáveis de saída (*outputs*)**

* `phft` (%): PHFT do modelo real
* `dif_phft` (%): diferença absoluta entre o PHFT do modelo real e do modelo de referência
  + $dif\_phft = phft_{real} - phft_{ref}$
* `cgtt` (kWh/ano): carga térmica total
* `dif_cgtt` (kWh/ano): diferença absoluta entre a CgTT do modelo real e do modelo de referência
  + $dif\_cgtt = cgtt_{real} - cgtt_{ref}$

###

***

### Limitações

É importante ressaltar que os modelos de predição compreendem melhor os casos que os alimentaram durante o treinamento. Portanto, visando gerar resultados mais acurados, recomenda-se a adoção de variáveis de entrada com valores próximos àqueles fornecidos na etapa de treinamento.

***

### Rotina de predição através do código *predict_outputs.r*

#### *Definição do ambiente de trabalho*

Inicialmente, os pacotes que serão utilizados durante a execução desse código serão carregados no ambiente de trabalho. Caso os pacotes tenham sido carregados corretamente no seu ambiente de trabalho, mensagens similares às mensagens acima devem surgir no seu console.

\

**Certifique-se de que a seção “Dependências” foi atendida exatamente como descrito. Isso deve evitar erros inesperados nas próximas etapas.**

\

``` {r}
# load packages
library(caret)
library(dplyr)
library(purrr)
```

\

Em seguida será carregado no ambiente de trabalho o arquivo com os metamodelos. Esse arquivo deve possuir o nome **models.rds** e estar localizado na mesma pasta do arquivo **predict_outputs.r**. Caso alguma dessas exigências não seja atendida, um erro surge na tela.

\

``` {r}
# load predictive models
if (file.exists('models.rds')) {
  models = readRDS('models.rds')
} else {
  stop(paste('O caminho para o arquivo com os metamodelos está',
             'incorreto. Confira se os arquivos predict_outputs.r',
             'e models.rds encontram-se no mesmo diretório.'))
}
```

\

#### *Definição das funções de predição*

Em seguida serão definidas as funções que realizam as predições de forma automatizada.

Para cada tipologia e cada variável de saída há um metamodelo (totalizando 8 metamodelos). A função `PredictOutput()` é encarregada de selecionar o metamodelo correspondente à variável de saída e à tipolgia desejadas e realiza as predições da variável de interesse. Essa função possui 3 argumentos: a) `targ` é a variável a ser predita ("phft", "dif_phft", "cgtt" ou "dif_cgtt"); b) `dummies` é o conjunto de dados de entrada após as transformação das variáveis qualitativas em variáveis lógicas; c) `typo` é a tipologia da edificação ("uni" ou "multi"). Após executada, `PredictOutput()` retorna um vetor com os valores das predições.

\

``` {r message = FALSE}
PredOutput = function(targ, dummies, typo) {
  # associate the target and typology with the related model and execute the predictions
  out = capture.output({
    predictions = models %>%
      pluck(typo, targ) %>%
      predict(newdata = dummies)
  })
  # return the predictions
  return(predictions)
}
```

\

A função `PredPerfUH()` possui 2 argumentos: a) `inputs` é a lista com o nome das variáveis de entrada e seus respectivos valores, ou o caminho (na máquina local) de um arquivo *csv* com os *inputs*; b) `data_path` é o caminho (na máquina local) onde o arquivo *csv* com os *inputs* e *outputs* deve ser salvo.

O argumento `data_path` possui valor pré-definido, isto é, caso esse argumento não seja preenchido o próprio código assume um valor padrão. O valor padrão de `data_path` é `data_path = 'data.csv'`, isto significa que um arquivo com o nome **data.csv** será salvo na mesma pasta onde encontra-se os arquivos **predict_outputs.r** e **models.rds**.

Inicialmente, a função `PredPerfUH()` confere se uma lista com as variáveis de entrada e os seus valores foi definida através do argumento `inputs`. Se uma lista foi inserida com mais de um valor para pelo menos uma das variáveis de entrada, ela é transformada em um *grid* com os valores listados. Caso não tenha sido inserida uma lista, a rotina confere se foi inserido um caminho válido para o arquivo *csv* contendo os *inputs*. Caso o caminho do arquivo *csv* seja inválido, o código gera um erro. Através do número de variáveis de entrada encontrado no argumento `inputs`, o código define a tipologia de interesse, sendo que **a tipologia unifamiliar exige valores de 12 variáveis de entrada**, enquanto **a tipologia multifamiliar necessita de 14 parâmetros de entrada**. Caso um número diferente de variáveis tenha sido inserido, o código é interrompido através de um erro. Em seguida, as transformações das variáveis lógicas são realizadas para que as predições das 4 variáveis de saída ("phft", "dif_phft", "cgtt" e "dif_cgtt") sejam estimadas em um *loop* sobre a função `PredictOutput()`, descrita anteriormente. Por fim, `PredPerfUH()` checa o valor inserido no argumento `data_path` e salva os dados com os *inputs* e *outputs* no caminho sugerido. Caso o diretório do caminho inserido pelo usuário no argumento `data_path` esteja incorreto, um erro surge no console. Após finalizada a rotina de cálculos, a função retorna uma tabela com os valores das variáveis de entrada e os respectivos valores das variáveis de saída.

\

``` {r message = FALSE}
PredPerfUH = function(inputs, data_path = 'data.csv') {
  # fit inputs into a grid data frame if no table was provided
  if (is.list(inputs)) {
    inputs = expand.grid(inputs)
  } else if (file.exists(inputs)) {
    inputs = read.csv(inputs)
  } else {
    stop(paste('Confira se o argumento "inputs" foi definido corretamente.\n',
               ' São aceitos apenas: a) uma lista com as variáveis de entrada',
               'e os seus respectivos valores; b) um caminho válido para a',
               'tabela/csv contendo os inputs.'))
  }
  # check if the number of inputs is correct and define the typology
  ncols = ncol(inputs)
  if (ncols == 12) {
    message('Variáveis de entrada referentes à tipologia unifamiliar.')
    typo = 'uni'
  } else if (ncols == 14) {
    message('Variáveis de entrada referentes à tipologia multifamiliar.')
    typo = 'multi'
  } else {
    stop(paste('Reveja as suas variáveis de entrada.',
               'Me parece que elas estão incorretas..!'))
  }
  # create dummy variables
  dummies = models[[c(typo, 'dummy_model')]] %>%
    predict(newdata = mutate(inputs, targ = NA)) %>%
    data.frame()
  # predict the outputs
  targs = c('phft', 'dif_phft', 'cgtt', 'dif_cgtt')
  predictions = targs %>%
    sapply(PredOutput, dummies, typo) %>%
    as.data.frame() %>%
    round(1)
  # pos-process
  if (nrow(inputs) == 1) {
    # adjust the data into proper dataframe
    data = predictions %>%
      rename(prediction = '.') %>%
      t() %>%
      as.data.frame()
  } else {
    # bind inputs and outputs to build the final data frame
    data = cbind(inputs, predictions)
  }
  # write a file containing inputs and outputs
  if (!is.null(data_path)) {
    if (dir.exists(dirname(data_path))) {
      write.csv(data, data_path, row.names = FALSE)
      message(paste('A tabela com os resultados foi salva em:',
                    normalizePath(data_path)))
    } else {
      stop(paste('O diretório para pra salvar a tabela com os resultados',
                 'me parece incorreto.\n  Confira se o caminho inserido',
                 'no argumento "data_path" realmente existe.'))
    }
  } else {
    message('A tabela com os resultados não foi salva.')
  }
  # return the data
  return(data)
}
```

\

#### *Exemplos de aplicação do código* {.tabset .tabset-pills}

Agora que os pacotes e metamodelos já foram carregadas no ambiente de trabalho e as funções necessárias já foram definidas, basta chamar a função `PredPerfUH()` preenchendo os argumentos necessários da maneira correta. Tanto listas quanto o caminho para um arquivo *csv* podem ser inseridos no argumento `inputs`.

\

##### **Lista** {.tabset}

A lista inserida no argumento `inputs` não precisa, necessariamente, ter valores únicos para cada uma das variáveis de entrada. É possível definir valores múltiplos para cada uma dessas variáveis. Quando definidos valores múltiplos para as variáveis de entrada, o código criará um *grid* considerando todos esses valores.

###### Valores únicos

Será definida uma lista de variáveis de entrada com apenas um valor para cada variável de entrada. Então, a função `PredPerfUH()` será executada, sendo que o argumento `inputs` será associado à lista de variáveis de entrada pré-definida no seu ambiente de trabalho.

\

``` {r}
inputs = list(
  area = 39,
  ratio = 0.5,
  pd = 2.5,
  azi = 180,
  comp = 'tv',
  vid = 'simples_fs87',
  abs = 0.4,
  paf = 30,
  fv = 0.45,
  ven = 'off',
  somb = 50,
  tbsm = 23.05
)
data = PredPerfUH(inputs)
```

\

Os resultados serão impressos no console para verificar se tudo saiu como o planejado.

\

``` {r eval = FALSE}
  print(data)
```

``` {r echo = FALSE}
  kable(data, align = 'c')
```

\

Note que, quando se insere uma lista com um valor único para cada variável de entrada, apenas os *outputs* são retornados.

###### Valores múltiplos

Será definida uma lista de variáveis de entrada com pelo menos uma das variáveis com mais de um valor. A função `PredPerfUH()` será então executada, associando o argumento `inputs` à lista de variáveis de entrada pré-definida no seu ambiente de trabalho.

\

``` {r}
inputs = list(
  area = 39,
  ratio = c(0.5, 2),
  pd = 2.5,
  azi = 180,
  comp = 'tv',
  vid = 'simples_fs87',
  abs = 0.2,
  paf = c(10, 30, 50),
  fv = 0.45,
  ven = 'off',
  somb = 50,
  tbsm = 23.05
)
data = PredPerfUH(inputs)
```

\

Os resultados serão impressos na tela.

\

``` {r eval = FALSE}
  print(data)
```

``` {r echo = FALSE}
  kable(data, align = 'c')
```

\

Observe que o *grid* que foi gerado trata-se de uma simples combinação de todas as variáveis contra todas.

##### **Caminho para o arquivo csv**

Será definido o caminho (na máquina local) para o arquivo *csv* com os *inputs* e, então, a função `PredPerfUH()`, associando o caminho pré-definido ao argumento `inputs`.

\

``` {r}
  inputs = 'inputs.csv'
  data = PredPerfUH(inputs)
  nrow(data)
```

\

Repare que a tabela de *inputs* inserida nesse exemplo possui 27668 observações (linhas), portanto, apenas as 20 primeiras linhas serão impressas.

\

``` {r eval = FALSE}
  print(head(data, 20))
```

``` {r echo = FALSE}
  kable(head(data, 20), align = 'c')
```

####

\

**Lembre-se sempre de checar se todas as variáveis relativas à tipologia de interesse (uni ou multifamiliar) foram inseridas e se os valores que foram inseridos são próximos daqueles utilizados na etapa de treinamento do metamodelo, descrita no item "Características dos metamodelos". Assim, assegura-se que as predições estarão corretas.**

\

#### *Salvando os resultados* {.tabset .tabset-pills}

A função `PredPerfUH()` salva automaticamente os resultados de forma padronizada no mesmo diretório onde encontram-se os arquivos **predict_outputs.r** e **models.rds**. Entretanto, o argumento `data_path` permite que se salvem os resultados com um nome alternativo ou, ainda, com um caminho alternativo até outro diretório. Se não for do interesse do usuário, é possível evitar que os resultados sejam salvos.

\

**Tenha muito cuidado, pois ao salvar os resultados qualquer arquivo no diretório que possua o mesmo nome definido no argumento `data_path` será sobrescrito e não poderá ser recuperado!** 

\

##### **Nome padrão**

A função `PredPerfUH()` salva os resultados automaticamente em um arquivo *csv* com o nome **data.csv**, na mesma pasta onde encontram-se os arquivos **predict_outputs** e **models.rds**.

A função `PredPerfUH()` simplesmente será executada sem preencher o argumento `data_path`.

\

``` {r}
  data = PredPerfUH('inputs.csv')
```

##### **Nome alternativo**

É possível definir um nome de arquivo personalizado preenchendo o argumento `data_path` com o nome desejado. Esse arquivo será salvo no mesmo diretório onde estão os arquivos **predict_outputs.r** e **models.rds**.

\

**O nome arquivo de saída, obrigatoriamente, deve possuir a extensão *csv*.**

\

A função `PredPerfUH()` será executada assumindo `data_path` a um nome alternativo.

\

``` {r}
  data_path = 'nome_do_arquivo.csv'
  data = PredPerfUH('inputs.csv', data_path)
```

##### **Caminho alternativo**

Caso seja necessário salvar o arquivo em um diretório diferente do diretório onde encontram-se os arquivos **predict_outputs** e **models.rds**, insira o caminho (na máquina local) onde se deseja-se salvar o arquivo.

\

**Se você é um usuário do sistema operacional Windows, lembre-se de trocar as *backslashes* (\\) por duas *backslashes* (\\), pois *backslashes* possuem funções especiais na linguagem R.**

\

A função `PredPerfUH()` será executada considerando um caminho alternativo no argumento `data_path`.

\

``` {r}
  data_path = '/home/rodox/Desktop/nome_do_arquivo.csv'
  data = PredPerfUH('inputs.csv', data_path)
```

##### **Não salvar**

Por fim, é possível orientar a função `PredPerfUH()` a não salvar o arquivo *csv*.

Para tanto, `PredPerfUH()` será executada considerando o argumento `data_path` como `data_path = NULL`.

\

``` {r}
  data = PredPerfUH('inputs.csv', NULL)
```
